# AI LLM Service

LLaMA-based medical AI for prescription enhancement and chatbot functionality.

## Architecture

```
ai-llm-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  # FastAPI entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model_loader.py      # LLaMA model loading
â”‚   â”‚   â””â”€â”€ generation.py        # Unified text generation
â”‚   â”‚
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ prescription/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ enhancer.py      # Prescription enhancement
â”‚   â”‚   â”‚   â””â”€â”€ validator.py     # Safety validation
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ chat/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ assistant.py     # Medical chatbot
â”‚   â”‚
â”‚   â””â”€â”€ safety/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ language.py          # Language validation
â”‚       â””â”€â”€ medical.py           # Medical safety constraints
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ llama/                   # Put GGUF model files here
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

## Prerequisites
- Python 3.10+
- (Optional) GPU drivers/CUDA for faster inference

## Setup
```bash
cd ai-llm-service
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Download LLaMA Model
Get a quantized GGUF model (e.g., llama-2-7b-chat.Q4_K_M.gguf) and place in `models/llama/` directory.

## Run
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8001
```

Open:
- API docs: http://localhost:8001/docs
- Health: http://localhost:8001/health

## API Endpoints

### POST /api/v1/enhance
Enhance prescription from OCR output

**Request:**
```json
{
  "ocr_result": {...},
  "language": "en"
}
```

### POST /api/v1/chat
Chat with medical assistant

**Request:**
```json
{
  "message": "What is this medicine for?",
  "history": [],
  "context": {...},
  "language": "en"
}
```

### POST /api/v1/validate
Validate prescription data

**Request:**
```json
{
  "prescription_data": {...}
}
```

## Implementation Status

ðŸš§ **Structure Ready - Implementation Pending**

All files are created with TODO markers for implementation.

## Key Features

âœ… Two distinct roles:
- **Prescription Enhancer**: Clean OCR â†’ Normalized data
- **Medical Chatbot**: Answer questions safely

âœ… Safety constraints:
- No diagnosis
- No prescription recommendations
- Medical disclaimer on all outputs

## Next Steps

1. Implement model loading in `model_loader.py`
2. Create generation logic in `generation.py`
3. Build prescription enhancer in `enhancer.py`
4. Add safety validators in `validator.py` and `medical.py`
5. Implement chatbot in `assistant.py`
6. Test with sample OCR outputs