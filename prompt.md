now help me to implement following phase below but i have implement it some code and build the structure file the goal is it scan presccription more accurate with advance image including complex some table, recongine symbole, units, mix of three language(english khmer and french) in one image. convert the raw data into clean medication and also generate the reminder.after done with that test it and it it error please check the database something it don't have the table for that so you can do the migration in the docker and restart database.  
PHASE 1 â€” OCR SERVICE (Document AI)

Goal of Phase 1

Convert prescription image â†’ structured OCR output with layout, rules, and confidence
NO LLM, NO correction by AI yet

âœ… Step 0: Environment Setup (Once)
1ï¸âƒ£ Create virtual environment
cd ocr-service
python -m venv venv
source venv/bin/activate

2ï¸âƒ£ requirements.txt (minimum)
fastapi
uvicorn
paddleocr
pillow
opencv-python
torch
transformers
pydantic
numpy


You can optimize later (CPU-only Torch if needed)

ğŸ§± Step 1: Define the OCR Output Contract (schemas.py)

ğŸ“ app/schemas.py

Why

Everything depends on this structure

LLM will consume this later

What to define

Bounding box

Text

Confidence

Layout group

from pydantic import BaseModel
from typing import List

class BoundingBox(BaseModel):
    x1: int
    y1: int
    x2: int
    y2: int

class OCRBlock(BaseModel):
    text: str
    box: BoundingBox
    confidence: float
    block_type: str  # header | body | table | footer

class OCRResult(BaseModel):
    language: str
    blocks: List[OCRBlock]


âœ… Do not skip this â€” this is your system backbone.

ğŸ” Step 2: OCR Engine (Text Extraction)

ğŸ“ app/ocr/paddle_engine.py

Responsibility

Image â†’ raw text + bounding boxes

No rules, no cleanup

What to implement

Load PaddleOCR

Run OCR

Normalize coordinates

from paddleocr import PaddleOCR

ocr = PaddleOCR(lang="en")  # later restrict to kh, en, fr

def run_ocr(image_path):
    result = ocr.ocr(image_path, cls=True)
    blocks = []

    for line in result[0]:
        box, (text, conf) = line
        blocks.append({
            "text": text,
            "box": box,
            "confidence": conf
        })
    return blocks


ğŸ“Œ Important

Do NOT clean text here

Keep raw OCR output

ğŸ§  Step 3: Layout Understanding (LayoutLMv3)

ğŸ“ app/layout/layoutlmv3.py

Responsibility

Understand document structure

Classify blocks (header, medicine list, dosage, notes)

What it consumes

OCR blocks + bounding boxes

What it outputs

Block classification

def classify_layout(ocr_blocks):
    """
    Input: OCR blocks with bbox
    Output: Same blocks with block_type
    """
    # Placeholder logic (replace with LayoutLMv3 inference)
    for block in ocr_blocks:
        block["block_type"] = "body"
    return ocr_blocks


ğŸ“Œ Key rule

LayoutLMv3 NEVER does OCR
It only understands structure

ğŸ§© Step 4: Grouping & Key-Value Logic

ğŸ“ app/layout/grouping.py
ğŸ“ app/layout/key_value.py

Grouping

Merge nearby blocks

Reconstruct medicine rows

def group_blocks(blocks):
    # group by Y proximity
    return blocks

Key-value

Detect patterns like:

Drug â†’ Dosage

Frequency â†’ Duration

def extract_key_values(blocks):
    return {
        "medicine": [],
        "dosage": []
    }


ğŸ“Œ This is rule-based, not AI.

ğŸ§¹ Step 5: Rule-Based Cleanup (Language-Specific)

ğŸ“ app/rules/medical_terms.py
ğŸ“ app/rules/khmer_fix.py

Responsibility

Fix OCR mistakes

Normalize spelling

DO NOT hallucinate

Example:

COMMON_FIXES = {
    "paracatamol": "paracetamol"
}

def fix_terms(text):
    for k, v in COMMON_FIXES.items():
        text = text.replace(k, v)
    return text

ğŸ“Š Step 6: Confidence Scoring

ğŸ“ app/confidence.py

Why

Medical system MUST expose uncertainty

def calculate_confidence(blocks):
    return sum(b["confidence"] for b in blocks) / len(blocks)

ğŸ” Step 7: Pipeline Orchestration

ğŸ“ app/pipeline.py

This is the heart of OCR service

from ocr.paddle_engine import run_ocr
from layout.layoutlmv3 import classify_layout
from rules.khmer_fix import fix_terms

def process_image(image_path):
    blocks = run_ocr(image_path)
    blocks = classify_layout(blocks)

    for b in blocks:
        b["text"] = fix_terms(b["text"])

    return blocks

ğŸšª Step 8: API Entry

ğŸ“ app/main.py

from fastapi import FastAPI, UploadFile
from pipeline import process_image

app = FastAPI()

@app.post("/ocr")
async def ocr(file: UploadFile):
    image_path = f"/tmp/{file.filename}"
    with open(image_path, "wb") as f:
        f.write(await file.read())

    blocks = process_image(image_path)
    return {"blocks": blocks}


âœ… Phase 1 DONE
You now have Document AI, not â€œjust OCRâ€.

ğŸ”· PHASE 2 â€” LLM SERVICE (LLaMA 8B / Ollama)

Goal

Structured reasoning over OCR output
Two roles: Prescription Enhancer + Chatbot

ğŸ§  Step 1: Model Loader (Core)

ğŸ“ app/core/model_loader.py

Responsibility

Load quantized LLaMA once

Reuse across requests

from llama_cpp import Llama

llm = Llama(
    model_path="models/llama/weights.gguf",
    n_ctx=4096,
    n_threads=8
)

ğŸ” Step 2: Unified Generation Logic

ğŸ“ app/core/generation.py

from core.model_loader import llm

def generate(prompt, max_tokens=512):
    output = llm(prompt, max_tokens=max_tokens)
    return output["choices"][0]["text"]


ğŸ“Œ Never call model directly elsewhere

ğŸ§¾ Step 3: Prescription Enhancer

ğŸ“ features/prescription/enhancer.py

Input

OCR structured JSON

Output

Clean, normalized prescription

from core.generation import generate

def enhance_prescription(ocr_json, prompt):
    return generate(prompt + str(ocr_json))

ğŸ§‘â€âš•ï¸ Step 4: Safety & Validation

ğŸ“ features/prescription/validator.py

def validate(text):
    forbidden = ["diagnose", "cure"]
    for word in forbidden:
        if word in text.lower():
            raise ValueError("Medical violation")

ğŸ’¬ Step 5: Chatbot Logic

ğŸ“ features/chat/assistant.py

def chat(message, memory):
    prompt = memory + "\nUser:" + message
    return generate(prompt)

ğŸ›¡ï¸ Step 6: Language & Safety Guards

ğŸ“ safety/language.py

ALLOWED = ["kh", "en", "fr"]


ğŸ“ safety/medical.py

No diagnosis

No drug advice

ğŸšª Step 7: API Entry

ğŸ“ app/main.py

from fastapi import FastAPI
from features.prescription.enhancer import enhance_prescription

app = FastAPI()

@app.post("/enhance")
def enhance(data: dict):
    return enhance_prescription(data)

âœ… FINAL RESULT

You now have:

âœ” Real Document AI (OCR + Layout)
âœ” Real LLM service (not tied to OCR)
âœ” Clean separation of responsibility
âœ” Safe medical constraints
âœ” Scalable future chatbot