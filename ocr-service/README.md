# OCR Service

<<<<<<< HEAD
Tesseract-based multilingual OCR service for extracting raw text from prescription images.

## Features

- **Multilingual OCR**: Khmer (khm), English (eng), French (fra)
- **Bounding Boxes**: Position and size of each detected text element
- **Confidence Scores**: Accuracy confidence for each element
- **Structure Metadata**: Block, paragraph, line, and word information
- **Image Preprocessing**: Denoising and adaptive thresholding

## Important Design Principle

This service provides **RAW OCR output only**:
- âœ… Extract text
- âœ… Keep bounding boxes
- âœ… Keep language mix
- âœ… Keep structure metadata

This service does **NOT**:
- âŒ Understand tables
- âŒ Understand medicine
- âŒ Translate languages
- âŒ Convert time
- âŒ Detect dosage
- âŒ Fix OCR errors

Use the AI/LLM service for text interpretation and correction.

## Prerequisites

### System Dependencies

```bash
# Install Tesseract OCR
sudo apt update
sudo apt install -y tesseract-ocr

# Install language packs (REQUIRED)
sudo apt install -y \
  tesseract-ocr-eng \
  tesseract-ocr-fra \
  tesseract-ocr-khm

# Verify installation
tesseract --list-langs
# Should show: eng, fra, khm
```

## Installation

### Using Virtual Environment

```bash
cd ocr-service

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
=======
Document AI service for prescription processing using PaddleOCR and LayoutLMv3.

## Architecture

```
ocr-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI entry point
â”‚   â”œâ”€â”€ schemas.py           # Data contracts (OCRBlock, OCRResult)
â”‚   â”œâ”€â”€ pipeline.py          # Pipeline orchestration
â”‚   â”œâ”€â”€ confidence.py        # Confidence scoring
â”‚   â”‚
â”‚   â”œâ”€â”€ ocr/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ paddle_engine.py # PaddleOCR text extraction
â”‚   â”‚
â”‚   â”œâ”€â”€ layout/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ layoutlmv3.py    # Document structure understanding
â”‚   â”‚   â”œâ”€â”€ grouping.py      # Block grouping logic
â”‚   â”‚   â””â”€â”€ key_value.py     # Key-value extraction
â”‚   â”‚
â”‚   â””â”€â”€ rules/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ medical_terms.py # Medical term corrections
â”‚       â””â”€â”€ khmer_fix.py     # Khmer-specific fixes
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Setup

1. Create virtual environment:
```bash
cd ocr-service
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. Install dependencies:
```bash
>>>>>>> 956213acb02fd8a10977582667da49fee5a0be8e
pip install -r requirements.txt

# Copy environment file
cp .env.example .env
```

<<<<<<< HEAD
### Using Docker

```bash
# Build image
docker build -t ocr-service .

# Run container
docker run -p 8002:8002 ocr-service
```

## Running the Service

### Development Mode

```bash
source venv/bin/activate
uvicorn app.main:app --host 0.0.0.0 --port 8002 --reload
```

### Production Mode

```bash
source venv/bin/activate
uvicorn app.main:app --host 0.0.0.0 --port 8002 --workers 4
```

## API Endpoints

### Health Check
```
GET /health
GET /api/v1/ocr/health
```

### Extract Text
```
POST /api/v1/ocr/extract
Content-Type: multipart/form-data

Parameters:
- file: Image file (required)
- apply_preprocessing: boolean (default: true)
- languages: string (default: "khm+eng+fra")
- include_low_confidence: boolean (default: true)
- include_stats: boolean (default: true)
```

### Extract and Save
```
POST /api/v1/ocr/extract-and-save
Content-Type: multipart/form-data

Parameters:
- file: Image file (required)
- output_name: string (optional, default: tesseract_result_{N})
- apply_preprocessing: boolean (default: true)
- languages: string (optional)
```

### Get Available Languages
```
GET /api/v1/ocr/languages
```

## Example Response

```json
{
  "success": true,
  "page": 1,
  "raw": [
    {
      "text": "áž›áŸáž”",
      "confidence": 92,
      "bbox": { "x": 120, "y": 450, "w": 50, "h": 20 },
      "block": 1,
      "paragraph": 1,
      "line": 1,
      "word": 1
    },
    {
      "text": "2x/day",
      "confidence": 85,
      "bbox": { "x": 320, "y": 450, "w": 80, "h": 22 },
      "block": 1,
      "paragraph": 1,
      "line": 1,
      "word": 2
    }
  ],
  "stats": {
    "total_words": 2,
    "avg_confidence": 88.5,
    "min_confidence": 85,
    "max_confidence": 92,
    "total_blocks": 1,
    "total_lines": 1
  },
  "languages_used": "khm+eng+fra"
}
```

## Configuration

See `.env.example` for all configuration options.

### Key Settings

| Variable | Description | Default |
|----------|-------------|---------|
| OCR_LANGUAGES | OCR language string | khm+eng+fra |
| OCR_OEM | OCR Engine Mode | 3 |
| OCR_PSM | Page Segmentation Mode | 6 |
| PORT | Service port | 8002 |

## Testing

```bash
# Using curl
curl -X POST "http://localhost:8002/api/v1/ocr/extract" \
  -F "file=@test_image.jpg"

# Using Python
import requests

with open("test_image.jpg", "rb") as f:
    response = requests.post(
        "http://localhost:8002/api/v1/ocr/extract",
        files={"file": f}
    )
print(response.json())
```

## Architecture

```
ocr-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ ocr.py           # OCR endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py        # Settings
â”‚   â”‚   â””â”€â”€ logger.py        # Logging
â”‚   â”œâ”€â”€ ocr/
â”‚   â”‚   â”œâ”€â”€ preprocess/
â”‚   â”‚   â”‚   â””â”€â”€ opencv.py    # Image preprocessing
â”‚   â”‚   â”œâ”€â”€ engines/
â”‚   â”‚   â”‚   â””â”€â”€ tesseract.py # Tesseract wrapper
â”‚   â”‚   â”œâ”€â”€ extractors/
â”‚   â”‚   â”‚   â””â”€â”€ raw_text.py  # Text extraction
â”‚   â”‚   â””â”€â”€ parsers/
â”‚   â”‚       â””â”€â”€ tesseract_parser.py  # Output parsing
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ bbox.py          # Bounding box model
â”‚   â”‚   â””â”€â”€ raw_ocr.py       # OCR response models
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ image.py         # Image utilities
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Future Improvements

1. **Custom Khmer Words**: Add user words file for improved Khmer recognition
   ```bash
   # Create tessdata/khm.user-words with common Khmer medical terms
   ```

2. **PDF Support**: Add PDF to image conversion

3. **Multi-page Documents**: Support batch processing

4. **GPU Acceleration**: Use CUDA for faster processing
=======
3. Run service:
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8002 --reload
```

## API Endpoints

### POST /ocr
Process prescription image with OCR

**Request:**
- Multipart form data with image file

**Response:**
```json
{
  "blocks": [
    {
      "text": "Paracetamol 500mg",
      "box": {"x1": 10, "y1": 20, "x2": 200, "y2": 40},
      "confidence": 0.95,
      "block_type": "body"
    }
  ]
}
```

## Implementation Status

ðŸš§ **Structure Ready - Implementation Pending**

All files are created with TODO markers for implementation.

## Next Steps

1. Implement PaddleOCR integration in `paddle_engine.py`
2. Add LayoutLMv3 model loading in `layoutlmv3.py`
3. Implement grouping algorithms in `grouping.py`
4. Build medical term dictionary in `medical_terms.py`
5. Connect pipeline in `pipeline.py`
6. Test with sample prescription images
>>>>>>> 956213acb02fd8a10977582667da49fee5a0be8e
